version: 2.1

parameters:
  benchmark:
    type: boolean
    default: false

executors:
  lint:
    docker:
      - image: ethereum/cpp-build-env:14-lint
  linux-gcc-9:
    docker:
      - image: ethereum/cpp-build-env:14-gcc-9
  linux-clang-latest:
    docker:
      - image: ethereum/cpp-build-env:14-clang-10
  macos:
    macos:
      xcode: 11.3.0

commands:
  build:
    description: "Build"
    parameters:
      target:
        type: string
        default: all
    steps:
      - run:
          name: "Environment"
          command: |
            CC=${CC:-cc}
            CXX=${CXX:-cpp}
            echo CC: $CC
            echo CXX: $CXX
            $CC --version
            $CXX --version
            cmake --version

            # Create the toolchain.info file for cache key.
            echo $TOOLCHAIN >> toolchain.info
            echo $BUILD_TYPE >> toolchain.info
            $CXX --version >> toolchain.info
      - restore_cache:
          name: "Restore Hunter cache"
          key: &hunter-cache-key hunter-{{arch}}-{{checksum "toolchain.info"}}-{{checksum "cmake/Hunter/init.cmake"}}
      - run:
          name: "Configure"
          working_directory: ~/build
          command: |
            cmake ../project -G Ninja -DCMAKE_INSTALL_PREFIX=~/install -DCMAKE_BUILD_TYPE=$BUILD_TYPE -DFIZZY_TESTING=ON $CMAKE_OPTIONS
      - save_cache:
          name: "Save Hunter cache"
          key: *hunter-cache-key
          paths:
            - ~/.hunter/_Base/Cache
      - run:
          name: "Build"
          command: cmake --build ~/build --target <<parameters.target>>

  test:
    description: "Test"
    steps:
    - run:
        name: "Test"
        working_directory: ~/build
        command: ctest -R ${TESTS_FILTER:-'.*'} -j4 --schedule-random --output-on-failure
    - run:
        name: "Run smoketest with fizzy-spectests --skip-validation"
        working_directory: ~/build
        environment:
          LLVM_PROFILE_FILE: spectests-validation.profraw
        command: bin/fizzy-spectests ~/project/test/spectests/smoketest --skip-validation
    - run:
        name: "Run smoketest with fizzy-spectests"
        working_directory: ~/build
        environment:
          LLVM_PROFILE_FILE: spectests-skipvalidation.profraw
        command: bin/fizzy-spectests ~/project/test/spectests/smoketest

  benchmark:
    description: "Run benchmarks"
    parameters:
      repetitions:
        type: integer
        default: 1
      min_time:
        type: string
        default: "0.5"
      out_dir:
        type: string
        default: out
    steps:
      - run:
          name: "Run wasm engine benchmarks"
          working_directory: ~/build
          command: bin/fizzy-bench ~/project/test/benchmarks --benchmark_repetitions=<<parameters.repetitions>> --benchmark_min_time=<<parameters.min_time>> --benchmark_out=engines-<<parameters.out_dir>>
      - run:
          name: "Run fizzy internal benchmarks"
          working_directory: ~/build
          command: bin/fizzy-bench-internal --benchmark_repetitions=<<parameters.repetitions>> --benchmark_min_time=<<parameters.min_time>> --benchmark_out=internal-<<parameters.out_dir>>

  spectest:
    description: "Run spectest"
    parameters:
      skip_validation:
        type: boolean
        default: false
      expected_passed:
        type: integer
      expected_failed:
        type: integer
        default: 0
      expected_skipped:
        type: integer
        default: 0

    steps:
      - run:
          name: "Download spectest files"
          working_directory: ~/build
          command: |
            if [ ! -d wasm-spec ]; then
              git clone https://github.com/wasmx/wasm-spec --branch vanilla-json --depth 1
            fi
      - run:
          name: "Run spectest<<#parameters.skip_validation>> (skip validation)<</parameters.skip_validation>>"
          working_directory: ~/build
          command: |
            set +e
            expected="  PASSED <<parameters.expected_passed>>, FAILED <<parameters.expected_failed>>, SKIPPED <<parameters.expected_skipped>>."
            result=$(bin/fizzy-spectests <<#parameters.skip_validation>>--skip-validation<</parameters.skip_validation>> wasm-spec/test/core/json | tail -1)
            if [ "$expected" != "$result" ]; then exit 1; fi

jobs:

  lint:
    executor: lint
    steps:
    - checkout
    - run:
        name: "Check code format"
        command: |
          clang-format --version
          find . -name '*.hpp' -o -name '*.cpp' -o -name '*.h' -o -name '*.c' -not -wholename './test/benchmarks/*' | xargs clang-format -i
          git diff --color --exit-code
    - run:
        name: "Run codespell"
        command: |
          codespell --quiet-level=4 -I .codespell-whitelist
    - run:
        name: "Install wabt"
        working_directory: ~/bin
        command: curl -L https://github.com/WebAssembly/wabt/releases/download/1.0.13/wabt-1.0.13-linux.tar.gz | tar xz --strip=1
    - run:
        name: "Check wat2wasm4cpp"
        command: |
          export PATH=$PATH:~/bin
          ./wat2wasm4cpp.py test/unittests/api_test.cpp
          ./wat2wasm4cpp.py test/unittests/end_to_end_test.cpp
          ./wat2wasm4cpp.py test/unittests/execute_call_test.cpp
          ./wat2wasm4cpp.py test/unittests/execute_control_test.cpp
          ./wat2wasm4cpp.py test/unittests/execute_numeric_test.cpp
          ./wat2wasm4cpp.py test/unittests/execute_test.cpp
          ./wat2wasm4cpp.py test/unittests/instantiate_test.cpp
          ./wat2wasm4cpp.py test/unittests/parser_test.cpp
          ./wat2wasm4cpp.py test/unittests/validation_stack_test.cpp
          ./wat2wasm4cpp.py test/unittests/validation_test.cpp
          ./wat2wasm4cpp.py test/unittests/wasm_engine_test.cpp
          ./wat2wasm4cpp.py test/spectests/spectests.cpp
          git diff --color --exit-code

  release-linux:
    executor: linux-gcc-9
    environment:
      BUILD_TYPE: Release
    steps:
      - checkout
      - build
      - test
      - persist_to_workspace:
          root: ~/build
          paths:
            - bin/fizzy-bench
            - bin/fizzy-spectests

  release-macos:
    executor: macos
    environment:
      BUILD_TYPE: Release
    steps:
      - run:
          name: "Install System Dependencies"
          command: HOMEBREW_NO_AUTO_UPDATE=1 brew install cmake ninja
      - checkout
      - build
      - test

  coverage-tidy:
    executor: linux-clang-latest
    environment:
      BUILD_TYPE: Coverage
      TESTS_FILTER: unittests
      CMAKE_OPTIONS: -DCMAKE_CXX_CLANG_TIDY=clang-tidy
    steps:
      - checkout
      - build
      - test
      - run:
          name: "Collect coverage data"
          working_directory: ~/build
          command: |
            mkdir coverage
            find -name '*.profraw'
            llvm-profdata merge *.profraw -o fizzy.profdata

            llvm-cov report -use-color -instr-profile fizzy.profdata -Xdemangler llvm-cxxfilt \
              -object bin/fizzy-unittests \
              -object bin/fizzy-spectests
            llvm-cov report -instr-profile fizzy.profdata -Xdemangler llvm-cxxfilt > coverage/report.txt \
              -object bin/fizzy-unittests \
              -object bin/fizzy-spectests

            llvm-cov show -format=html -instr-profile fizzy.profdata -Xdemangler llvm-cxxfilt -region-coverage-lt=100 > coverage/missing.html \
              -object bin/fizzy-unittests \
              -object bin/fizzy-spectests
            llvm-cov show -format=html -instr-profile fizzy.profdata -Xdemangler llvm-cxxfilt > coverage/full.html \
              -object bin/fizzy-unittests \
              -object bin/fizzy-spectests

            llvm-cov export -instr-profile fizzy.profdata -format=lcov > fizzy.lcov \
              -object bin/fizzy-unittests \
              -object bin/fizzy-spectests
            genhtml fizzy.lcov -o coverage -t Fizzy
      - store_artifacts:
          path: ~/build/coverage
          destination: coverage
      - run:
          name: "Upload to Codecov"
          command: |
            # Convert to relative paths
            sed -i 's|$(pwd)/||' ~/build/fizzy.lcov
            codecov --file ~/build/fizzy.lcov -X gcov

  sanitizers:
    executor: linux-clang-latest
    environment:
      BUILD_TYPE: RelWithDebInfo
      CMAKE_OPTIONS: -DENABLE_ASSERTIONS=ON -DSANITIZE=address,undefined,nullability,implicit-unsigned-integer-truncation,implicit-signed-integer-truncation
      UBSAN_OPTIONS: halt_on_error=1
    steps:
      - checkout
      - build
      - test
      - benchmark:
          min_time: "0.01"
      - spectest:
          expected_passed: 4747
          expected_failed: 685
          expected_skipped: 6381

  benchmark:
    machine:
      image: ubuntu-1604:201903-01
    environment:
      CC: gcc-9
      CXX: g++-9
      BUILD_TYPE: Release
    steps:
      - run:
          name: "Install benchmark compare.py"
          working_directory: "~"
          command: |
            git clone https://github.com/google/benchmark.git --quiet --depth=1 --single-branch
            pyenv global 3.7.0
            pip install scipy --progress-bar off
            python ~/benchmark/tools/compare.py --help
      - run:
          name: "Install toolchain"
          working_directory: "~"
          command: |
            export DEBIAN_FRONTEND=noninteractive

            # Remove additional sources
            sudo rm /etc/apt/sources.list.d/*

            wget -O - https://apt.kitware.com/keys/kitware-archive-latest.asc 2>/dev/null | sudo apt-key add -

            sudo add-apt-repository ppa:ubuntu-toolchain-r/test
            sudo apt-add-repository 'deb https://apt.kitware.com/ubuntu/ xenial main'
            sudo apt-get -q update
            sudo apt-get -qy install --no-install-recommends g++-9 cmake ninja-build

      - checkout
      - build:
          target: fizzy-bench fizzy-bench-internal
      - benchmark:
          repetitions: 9
          out_dir: new
      - run:
          name: "Checkout base"
          command: git checkout $(git merge-base HEAD origin/master)
      - build:
          target: fizzy-bench fizzy-bench-internal
      - benchmark:
          repetitions: 9
          out_dir: old
      - run:
          name: "Compare"
          working_directory: "~"
          command: |
            benchmark/tools/compare.py --display_aggregates_only benchmarks ~/build/engines-old ~/build/engines-new
            benchmark/tools/compare.py --display_aggregates_only benchmarks ~/build/internal-old ~/build/internal-new

  fuzzing:
    executor: linux-clang-latest
    environment:
      BUILD_TYPE: RelWithDebInfo
      CMAKE_OPTIONS: -DFIZZY_FUZZING=ON -DENABLE_ASSERTIONS=ON
      UBSAN_OPTIONS: halt_on_error=1
    steps:
      - checkout
      - build
      - restore_cache:
          name: "Restore fuzzing corpus"
          key: fuzzing-corpus
      - run:
          name: "Parser fuzzing"
          working_directory: ~/build
          command: |
            mkdir -p corpus
            bin/fizzy-fuzz-parser corpus -jobs=8 -runs=1000000 -max_len=1024 -len_control=100000 -use_value_profile=1 -print_final_stats=1
            mv corpus corpus-full
            mkdir corpus
            echo '--- MERGE ---'
            bin/fizzy-fuzz-parser -merge=1 corpus corpus-full
      - save_cache:
          name: "Save fuzzing corpus"
          key: fuzzing-corpus-{{epoch}}
          paths:
            - ~/build/corpus

  spectest:
    executor: linux-gcc-9
    steps:
      - attach_workspace:
          at: ~/build
      - spectest:
          skip_validation: true
          expected_passed: 4482
          expected_failed: 8
          expected_skipped: 7323
      - spectest:
          expected_passed: 4747
          expected_failed: 685
          expected_skipped: 6381

workflows:
  version: 2

  testing:
    unless: <<pipeline.parameters.benchmark>>
    jobs:
      - lint
      - release-linux
      - release-macos
      - coverage-tidy
      - sanitizers
      - fuzzing
      - spectest:
          requires:
            - release-linux

  benchmarking:
    when: <<pipeline.parameters.benchmark>>
    jobs:
      - benchmark
